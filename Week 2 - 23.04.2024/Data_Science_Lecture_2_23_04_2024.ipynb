{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Regular Expressions and Basics of Text Analysis\n",
        "\n",
        "This week, we will be learning Regular Expressions (regex) and how we can use them in our research."
      ],
      "metadata": {
        "id": "jIuqJ5-jhIcV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52eH2Dz2g2bl"
      },
      "outputs": [],
      "source": [
        "# Regular Expressions in Python can be used by the \"re\" library.\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In the re library you can use several options.\n",
        "\n",
        "re.search(pattern, text)\n",
        "\n",
        "# You can also look for a match and get a 'match' object as a result.\n",
        "\n",
        "re.match(pattern, sequence)"
      ],
      "metadata": {
        "id": "Z3tVZRnXh9RD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Most likely you will search for a pattern\n",
        "pattern = 'Science'\n",
        "text = 'Data Science'\n",
        "\n",
        "if re.search(pattern, text):\n",
        "    print(\"Match! I found \",pattern)\n",
        "else: print(\"Not a match!\")"
      ],
      "metadata": {
        "id": "FtCFkQ9bcOXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.search(pattern, text)"
      ],
      "metadata": {
        "id": "XFhtx8Rw7Jdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using only the .search or .match options are going to give you an object as a\n",
        "# result, which could be difficult to interpret. You can use .group option to\n",
        "# get around this.\n",
        "\n",
        "re.search(r'.', 'Cookie').group()"
      ],
      "metadata": {
        "id": "O2y71uNUlT6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Patterns - https://developers.google.com/edu/python/regular-expressions\n",
        "\n",
        "The power of regular expressions is that they can specify patterns, not just fixed characters. Here are the most basic patterns which match single chars:\n",
        "\n",
        "    a, X, 9, < -- ordinary characters just match themselves exactly. The meta-characters which do not match themselves because they have special meanings are: . ^ $ * + ? { [ ] \\ | ( ) (details below)\n",
        "    . (a period) -- matches any single character except newline '\\n'\n",
        "    \\w -- (lowercase w) matches a \"word\" character: a letter or digit or underbar [a-zA-Z0-9_]. Note that although \"word\" is the mnemonic for this, it only matches a single word char, not a whole word. \\W (upper case W) matches any non-word character.\n",
        "    \\b -- boundary between word and non-word\n",
        "    \\s -- (lowercase s) matches a single whitespace character -- space, newline, return, tab, form [ \\n\\r\\t\\f]. \\S (upper case S) matches any non-whitespace character.\n",
        "    \\t, \\n, \\r -- tab, newline, return\n",
        "    \\d -- decimal digit [0-9] (some older regex utilities do not support \\d, but they all support \\w and \\s)\n",
        "    ^ = start, $ = end -- match the start or end of the string\n",
        "    \\ -- inhibit the \"specialness\" of a character. So, for example, use \\. to match a period or \\\\ to match a slash. If you are unsure if a character has special meaning, such as '@', you can try putting a slash in front of it, \\@. If its not a valid escape sequence, like \\c, your python program will halt with an error."
      ],
      "metadata": {
        "id": "81Lh25MNa0kE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's have a look at some of these patterns and how they might be useful to us.\n",
        "# https://www.datacamp.com/tutorial/python-regular-expression-tutorial\n",
        "re.search(r'^Eat', \"Eat cake!\").group()\n",
        "\n",
        "re.search(r'^Eat', \"Let's Eat cake!\").group()"
      ],
      "metadata": {
        "id": "3iPA_-2-mK2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also look for the end of a string.\n",
        "re.search(r'cake$', \"Cake! Let's eat cake\").group()\n",
        "\n",
        "re.search(r'cake$', \"Let's get some cake on our way home!\").group()"
      ],
      "metadata": {
        "id": "e9UGPd92TZB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mini Assignment: Write a regex pattern that looks for the beginning and the end of your first name, and make it match.\n",
        "\n",
        "# Your code here...\n",
        "last_c = re.search('M.+a', \"Mustafa\").group()\n",
        "last_name = re.search('türk', 'Öztürk').group()"
      ],
      "metadata": {
        "id": "cB6_Isufpffq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The most likely application of regular expressions is looking for text systematically. For this, you will have to use brackets.\n",
        "re.search('O*', 'FOObar')"
      ],
      "metadata": {
        "id": "d7zpA6zyTgA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.search('[0-9]\\s[0-9]', 'foo123bar')"
      ],
      "metadata": {
        "id": "AIYc-A4a-N-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.search('[0-9a-fA-f]', '--- a0 ---')"
      ],
      "metadata": {
        "id": "BL_3b5Vl-OkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look for the first digit in front of the string.\n",
        "re.search('[^a-z]', '12345foo')"
      ],
      "metadata": {
        "id": "lO7w4tMByXS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backslashes are going to be the most used and the most forgotten of all.\n",
        "re.search('[ab\\&cd]', 'foo[1]')"
      ],
      "metadata": {
        "id": "eodZ_3Kzyepq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following are the important patterns that you will use.\n",
        "# 1- Dot (.)\n",
        "# The dot implies a wildcard in the text. If you want to look for cake, you can simply ask for \"c.ke\". But since it is a wildcard, you might get a result \"coke\".\n",
        "re.search('foo.bar', 'fooxbar')\n",
        "print(re.search('foo.bar', 'foobar'))\n",
        "print(re.search('foo.bar', 'foo\\nbar'))"
      ],
      "metadata": {
        "id": "HCI_AQ-ry5a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# An example from https://www.geeksforgeeks.org/regular-expression-python-examples/\n",
        "s = 'geeks.forgeeks'\n",
        "\n",
        "# without using \\\n",
        "match = re.search(r'.', s)\n",
        "print(match)\n",
        "\n",
        "# using \\\n",
        "match = re.search(r's\\.f', s)\n",
        "print(match)"
      ],
      "metadata": {
        "id": "2P7-DnOX7BMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Case Study from: https://www.datacamp.com/tutorial/python-regular-expression-tutorial\n",
        "import requests\n",
        "the_idiot_url = 'https://www.gutenberg.org/files/2638/2638-0.txt'\n",
        "\n",
        "def do_something(url):\n",
        "    # Sends a http request to get the text from project Gutenberg\n",
        "    raw = requests.get(url).text\n",
        "    # Discards the metadata from the beginning of the book\n",
        "    start = re.search(\"\\*\\*\\* START OF THE PROJECT GUTENBERG EBOOK THE IDIOT \\*\\*\\*\", raw).end()\n",
        "    # Discards the text starting Part 2 of the book\n",
        "    stop = re.search(\"II\\.\", raw).start()\n",
        "    # Keeps the relevant text\n",
        "    text = raw[start:stop]\n",
        "    return text\n",
        "\n",
        "def preprocess(sentence):\n",
        "    return re.sub('[^A-Za-z0-9.]+' , ' ', sentence).lower()\n",
        "\n",
        "book = do_something(the_idiot_url)\n",
        "processed_book = preprocess(book)\n",
        "print(processed_book)"
      ],
      "metadata": {
        "id": "JNDOpA35AG54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "requests.get('https://www.gutenberg.org/files/2638/2638-0.txt').text"
      ],
      "metadata": {
        "id": "MM8E0MGqDbHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many times the word \"the\" have been used in the book?\n",
        "len(re.findall(r'the', processed_book))"
      ],
      "metadata": {
        "id": "f71Zu5J5gSUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all the standalone \"i\" to \"I\" in the book, but not the \"i\" inside a word. (You need to use \\s)\n",
        "processed_book = re.sub(r'\\si\\s', \" I \", processed_book)"
      ],
      "metadata": {
        "id": "CBkpErcJgUms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the number of times anyone was quoted (\"\") in the corpus.\n",
        "len(re.findall(r'\\”', book))"
      ],
      "metadata": {
        "id": "hZcmMrN1gYGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignment 1: Write a regular expression that would find you an e-mail address. This is not intended to make you a scammer.\n",
        "\n",
        "# Your code here...\n",
        "\n",
        "# pattern = ..."
      ],
      "metadata": {
        "id": "vHHAuI4of7PN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us work on a real-life example that I had to do a couple weeks ago.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('https://raw.githubusercontent.com/timuroeztuerk/data-science-lecture-S24/main/Datasets/GermanyKreiseToClean.xlsx')"
      ],
      "metadata": {
        "id": "1eEZ6oknf-WI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The task is to clean all \"1.\" or \"9.\" etc. as well as anything in parantheses. Without coding could you come up with a plan for the computer on what to do?\n",
        "\n",
        "df_test = df.iloc[:,0].apply(lambda x: re.sub(r'^\\d+\\.\\s*|\\s*\\(.+\\)$', '', str(x)))"
      ],
      "metadata": {
        "id": "8RCcGyejp3rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Short Introduction to NLTK and Tokenization\n",
        "\n",
        "NLTK is a powerful library in Python for working with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning. It's widely used for prototyping and building research systems.\n",
        "\n",
        "Tokenization in natural language processing (NLP) is the process of splitting text into smaller units, called tokens. These tokens can be words, sentences, or even parts of words. It's a fundamental step because it helps in simplifying the text data, making it easier to analyze or process for tasks like sentiment analysis, topic modeling, or information extraction.\n",
        "\n",
        "The following code blocks were taken with modifications from DataCamp."
      ],
      "metadata": {
        "id": "yfMYjG98kZjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from  nltk.tokenize import word_tokenize\n",
        "from  nltk.tokenize import sent_tokenize\n",
        "import requests"
      ],
      "metadata": {
        "id": "iPMqqFeElo1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the first scene from Monty Pythons Holy Grail.\n",
        "scene_one = requests.get(r\"https://raw.githubusercontent.com/timuroeztuerk/data-science-lecture-S24/main/Datasets/MontyPython.txt\").text\n",
        "\n",
        "# Split scene_one into sentences: sentences\n",
        "sentences = sent_tokenize(scene_one)\n",
        "\n",
        "# Use word_tokenize to tokenize the fourth sentence: tokenized_sent\n",
        "tokenized_sent = word_tokenize(sentences[3])\n",
        "\n",
        "# Make a set of unique tokens in the entire scene: unique_tokens\n",
        "unique_tokens = set(word_tokenize(scene_one))\n",
        "\n",
        "# Print the unique tokens result\n",
        "print(unique_tokens)"
      ],
      "metadata": {
        "id": "vEIxnJSOkph5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How would you use regex here to parse the text when the soldier speaks? Give me a regex example.\n",
        "my_string = \"SOLDIER #1: Found them? In Mercea? The coconut's tropical!\"\n",
        "\n",
        "# Your code/answer here..."
      ],
      "metadata": {
        "id": "e5I7dW65lzph"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}